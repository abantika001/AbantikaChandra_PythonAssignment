{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "m-dprgyTOU9b"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import csv\n",
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "from bs4 import BeautifulSoup\n",
        "from zipfile import ZipFile\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Xcq44M7WPE-D"
      },
      "outputs": [],
      "source": [
        "# download xml file\n",
        "def download_file(save_location,url,file_name):\n",
        "  \n",
        "  local_filename = save_location + file_name\n",
        "  \n",
        "  with requests.get(url, stream=True) as r:\n",
        "    r.raise_for_status()\n",
        "    with open(local_filename, 'wb') as f:\n",
        "      for chunk in r.iter_content(chunk_size=1024):  \n",
        "        f.write(chunk)\n",
        "  return (local_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "F8byuLZi-7Lf"
      },
      "outputs": [],
      "source": [
        "# get zip file\n",
        "def get_zip_url(xml_file_path):\n",
        "  \n",
        "  \n",
        "  empty_list=[]\n",
        "  \n",
        "  f = open(xml_file_path, 'r')\n",
        "  \n",
        "  xml_file = f.read()\n",
        "  \n",
        "  soup = BeautifulSoup(xml_file, 'lxml')\n",
        "  \n",
        "  \n",
        "  for tag in soup.findAll(\"str\"):\n",
        "    \n",
        "    if tag[\"name\"] == 'download_link':\n",
        "      empty_list.append(tag.text)\n",
        "  return empty_list\n",
        "  \n",
        "  f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EXR76Lin8uC6"
      },
      "outputs": [],
      "source": [
        "# Creating CSV from XML File\n",
        "def create_csv(xml_file, csv_path):\n",
        "    try:\n",
        "        # Checking if the path exists or not\n",
        "        if not os.path.exists(csv_path):\n",
        "            # Creating the path\n",
        "            logging.warning(\"Creating CSV file path\")\n",
        "            os.makedirs(csv_path)\n",
        "\n",
        "        # Extracting the csv file name from xml file\n",
        "        csv_fname = xml_file.split(os.sep)[-1].split(\".\")[0] + \".csv\"\n",
        "\n",
        "        # Creating csv file path\n",
        "        csv_file = os.path.join(csv_path, csv_fname)\n",
        "\n",
        "        logging.warning(\"Loading the xml file\")\n",
        "        # Creating xml file itertor\n",
        "        xml_iter = ET.iterparse(xml_file, events=(\"start\",))\n",
        "\n",
        "        csv_columns = [\n",
        "            \"FinInstrmGnlAttrbts.Id\",\n",
        "            \"FinInstrmGnlAttrbts.FullNm\",\n",
        "            \"FinInstrmGnlAttrbts.ClssfctnTp\",\n",
        "            \"FinInstrmGnlAttrbts.CmmdtyDerivInd\",\n",
        "            \"FinInstrmGnlAttrbts.NtnlCcy\",\n",
        "            \"Issr\",\n",
        "        ]\n",
        "\n",
        "        # Creating empty dataframe with the required column names\n",
        "        df = pd.DataFrame(columns=csv_columns)\n",
        "\n",
        "        # List to store the extacted data\n",
        "        extracted_data = []\n",
        "\n",
        "        logging.warning(\"Parsing the xml file...\")\n",
        "        logging.warning(\"Extracting the required data from xml\")\n",
        "        # Traversing the xml data\n",
        "        for event, element in xml_iter:\n",
        "\n",
        "            # Checking for start of the tags\n",
        "            if event == \"start\":\n",
        "\n",
        "                # Checking for TermntdRcrd tag in which the required data is\n",
        "                if \"TermntdRcrd\" in element.tag:\n",
        "\n",
        "                    # Dictionary to store require data in single element\n",
        "                    data = {}\n",
        "\n",
        "                    # List of the required tags (FinInstrmGnlAttrbts, Issr)\n",
        "                    reqd_elements = [\n",
        "                        (elem.tag, elem)\n",
        "                        for elem in element\n",
        "                        if \"FinInstrmGnlAttrbts\" in elem.tag or \"Issr\" in elem.tag\n",
        "                    ]\n",
        "\n",
        "                    # Traversing through the required tags\n",
        "                    for tag, elem in reqd_elements:\n",
        "\n",
        "                        if \"FinInstrmGnlAttrbts\" in tag:\n",
        "\n",
        "                            # Traversing through the child elements of\n",
        "                            # FinInstrmGnlAttrbts element\n",
        "                            for child in elem:\n",
        "\n",
        "                                # Adding the extrcated data in the dictionary\n",
        "                                if \"Id\" in child.tag:\n",
        "                                    data[csv_columns[0]] = child.text\n",
        "                                elif \"FullNm\" in child.tag:\n",
        "                                    data[csv_columns[1]] = child.text\n",
        "                                elif \"ClssfctnTp\" in child.tag:\n",
        "                                    data[csv_columns[2]] = child.text\n",
        "                                elif \"CmmdtyDerivInd\" in child.tag:\n",
        "                                    data[csv_columns[3]] = child.text\n",
        "                                elif \"NtnlCcy\" in child.tag:\n",
        "                                    data[csv_columns[4]] = child.text\n",
        "\n",
        "                        # Extracting Issr Tag value\n",
        "                        else:\n",
        "                            data[csv_columns[5]] = child.text\n",
        "\n",
        "                    # Appending the single element extracted data in the list\n",
        "                    extracted_data.append(data)\n",
        "\n",
        "        logging.warning(\"All the required data extracted from xml file\")\n",
        "\n",
        "        # Appending the extracted data in the data frame\n",
        "        df = df.append(extracted_data, ignore_index=True)\n",
        "\n",
        "        logging.warning(\"Dropping empty rows\")\n",
        "        # Removes empty rows from the dataframe\n",
        "        df.dropna(inplace=True)\n",
        "\n",
        "        logging.warning(\"Creating the CSV file\")\n",
        "        # Creates csv file from the dataframe\n",
        "        df.to_csv(csv_file, index=False)\n",
        "\n",
        "        # returning the csv file path\n",
        "        return csv_file\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error occurred while extracting - {str(e)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_qDuLGy0Mj3B"
      },
      "outputs": [],
      "source": [
        "def extract_zip(url_zip,save_location):\n",
        "  '''function to extract zip file to a directory'''\n",
        "\n",
        "\n",
        "  # specifying the zip file name\n",
        "  file_name = url_zip\n",
        "  loc = save_location\n",
        "  \n",
        "  # opening the zip file in READ mode\n",
        "  with ZipFile(file_name, 'r') as zip:\n",
        "    # printing all the contents of the zip file\n",
        "    zip.printdir()\n",
        "    \n",
        "    # extracting all the files\n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall(path=loc)\n",
        "    print('Done!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7cBYPiCwB6IK"
      },
      "outputs": [],
      "source": [
        "#URL from where XML will be downloaded\n",
        "url_path='https://registers.esma.europa.eu/solr/esma_registers_firds_files/select?q=*&fq=publication_date:%5B2021-01-17T00:00:00Z+TO+2021-01-19T23:59:59Z%5D&wt=xml&indent=true&start=0&rows=100'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "angc8e0nC0qx"
      },
      "outputs": [],
      "source": [
        "save_location = './Data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "h0R80XCA_ZBx"
      },
      "outputs": [],
      "source": [
        "#xml file location \n",
        "xml_loc = save_location + 'xml_file.xml'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vhSMw53hMKkE",
        "outputId": "e7102f78-19b8-4595-a1ab-ae0c6fc342b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'./Data/xml_file.xml'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#download and save \n",
        "download_file(save_location,url_path,'xml_file.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyI0yfuJ_SUZ"
      },
      "outputs": [],
      "source": [
        "zip_url_list = get_zip_url(xml_loc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbeDqL5aAIp3",
        "outputId": "08d763c5-a088-450f-ecb5-596c693bd4cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['http://firds.esma.europa.eu/firds/DLTINS_20210117_01of01.zip',\n",
              " 'http://firds.esma.europa.eu/firds/DLTINS_20210119_01of02.zip',\n",
              " 'http://firds.esma.europa.eu/firds/DLTINS_20210119_02of02.zip',\n",
              " 'http://firds.esma.europa.eu/firds/DLTINS_20210118_01of01.zip']"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zip_url_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "n-vKxo8NCi1P"
      },
      "outputs": [],
      "source": [
        "for i in range(len(zip_url_list)):\n",
        "  download_file(save_location,zip_url_list[i],'zipfile'+str(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy5Y1cMRM4PF",
        "outputId": "b0bec732-072d-4f1e-fcd3-9f8fa8a98e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File Name                                             Modified             Size\n",
            "DLTINS_20210117_01of01.xml                     2021-01-17 01:17:12    143278061\n",
            "Extracting all the files now...\n",
            "Done!\n",
            "File Name                                             Modified             Size\n",
            "DLTINS_20210119_01of02.xml                     2021-01-19 03:21:08    521464972\n",
            "Extracting all the files now...\n",
            "Done!\n",
            "File Name                                             Modified             Size\n",
            "DLTINS_20210119_02of02.xml                     2021-01-19 03:21:56    363082618\n",
            "Extracting all the files now...\n",
            "Done!\n",
            "File Name                                             Modified             Size\n",
            "DLTINS_20210118_01of01.xml                     2021-01-18 01:21:22      1439631\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "for i in range(4):\n",
        "  extract_zip(save_location + '/zipfile'+ str(i), save_location)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-ZUUIdg87YK7"
      },
      "outputs": [],
      "source": [
        "input_extracted_xml=[\"./Data/DLTINS_20210117_01of01.xml\",\n",
        "                     \"./Data/DLTINS_20210118_01of01.xml\",\n",
        "                     \"./Data/DLTINS_20210119_01of02.xml\",\n",
        "                     \"./Data/DLTINS_20210119_02of02.xml\"]\n",
        "\n",
        "output_path_converted_csv=\"./Data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "byrt0UrM_5F5"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUfPvm_294bL",
        "outputId": "75ff8da8-47ba-4cf0-e8cc-706c859955bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:Loading the xml file\n",
            "WARNING:root:Parsing the xml file...\n",
            "WARNING:root:Extracting the required data from xml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./Data/DLTINS_20210117_01of01.xml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:All the required data extracted from xml file\n",
            "/var/folders/p6/p3tv6kqx7gd_zbl_rycdv0th0000gn/T/ipykernel_20118/2779336562.py:87: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(extracted_data, ignore_index=True)\n",
            "WARNING:root:Dropping empty rows\n",
            "WARNING:root:Creating the CSV file\n",
            "WARNING:root:Loading the xml file\n",
            "WARNING:root:Parsing the xml file...\n",
            "WARNING:root:Extracting the required data from xml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./Data/DLTINS_20210118_01of01.xml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:All the required data extracted from xml file\n",
            "/var/folders/p6/p3tv6kqx7gd_zbl_rycdv0th0000gn/T/ipykernel_20118/2779336562.py:87: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(extracted_data, ignore_index=True)\n",
            "WARNING:root:Dropping empty rows\n",
            "WARNING:root:Creating the CSV file\n",
            "WARNING:root:Loading the xml file\n",
            "WARNING:root:Parsing the xml file...\n",
            "WARNING:root:Extracting the required data from xml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./Data/DLTINS_20210119_01of02.xml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:All the required data extracted from xml file\n",
            "/var/folders/p6/p3tv6kqx7gd_zbl_rycdv0th0000gn/T/ipykernel_20118/2779336562.py:87: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(extracted_data, ignore_index=True)\n",
            "WARNING:root:Dropping empty rows\n",
            "WARNING:root:Creating the CSV file\n",
            "WARNING:root:Loading the xml file\n",
            "WARNING:root:Parsing the xml file...\n",
            "WARNING:root:Extracting the required data from xml\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "./Data/DLTINS_20210119_02of02.xml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:All the required data extracted from xml file\n",
            "/var/folders/p6/p3tv6kqx7gd_zbl_rycdv0th0000gn/T/ipykernel_20118/2779336562.py:87: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  df = df.append(extracted_data, ignore_index=True)\n",
            "WARNING:root:Dropping empty rows\n",
            "WARNING:root:Creating the CSV file\n"
          ]
        }
      ],
      "source": [
        "for link in input_extracted_xml:\n",
        "  print(link)\n",
        "  \n",
        "  create_csv(link, output_path_converted_csv)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "eIburtOEIYOg"
      },
      "source": [
        "# Check CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "dddVkJ8mHwap"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('./Data/DLTINS_20210119_01of02.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6QM2gZ_H20p",
        "outputId": "98f4082c-6bf1-47b8-c54b-9f079cc40377"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23316 entries, 0 to 23315\n",
            "Data columns (total 6 columns):\n",
            " #   Column                              Non-Null Count  Dtype \n",
            "---  ------                              --------------  ----- \n",
            " 0   FinInstrmGnlAttrbts.Id              23316 non-null  object\n",
            " 1   FinInstrmGnlAttrbts.FullNm          23316 non-null  object\n",
            " 2   FinInstrmGnlAttrbts.ClssfctnTp      23316 non-null  object\n",
            " 3   FinInstrmGnlAttrbts.CmmdtyDerivInd  23316 non-null  bool  \n",
            " 4   FinInstrmGnlAttrbts.NtnlCcy         23316 non-null  object\n",
            " 5   Issr                                23316 non-null  bool  \n",
            "dtypes: bool(2), object(4)\n",
            "memory usage: 774.3+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "Bm9JeKUZH9GY",
        "outputId": "617dda35-f6c8-4a77-9363-c31453960b62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FinInstrmGnlAttrbts.Id</th>\n",
              "      <th>FinInstrmGnlAttrbts.FullNm</th>\n",
              "      <th>FinInstrmGnlAttrbts.ClssfctnTp</th>\n",
              "      <th>FinInstrmGnlAttrbts.CmmdtyDerivInd</th>\n",
              "      <th>FinInstrmGnlAttrbts.NtnlCcy</th>\n",
              "      <th>Issr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>DE000MA40TG3</td>\n",
              "      <td>Open End Turbo Long Fresenius emittiert von Mo...</td>\n",
              "      <td>RFSTCA</td>\n",
              "      <td>False</td>\n",
              "      <td>EUR</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DE000MA40TH1</td>\n",
              "      <td>Open End Turbo Long Fresenius emittiert von Mo...</td>\n",
              "      <td>RFSTCA</td>\n",
              "      <td>False</td>\n",
              "      <td>EUR</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  FinInstrmGnlAttrbts.Id                         FinInstrmGnlAttrbts.FullNm  \\\n",
              "0           DE000MA40TG3  Open End Turbo Long Fresenius emittiert von Mo...   \n",
              "1           DE000MA40TH1  Open End Turbo Long Fresenius emittiert von Mo...   \n",
              "\n",
              "  FinInstrmGnlAttrbts.ClssfctnTp  FinInstrmGnlAttrbts.CmmdtyDerivInd  \\\n",
              "0                         RFSTCA                               False   \n",
              "1                         RFSTCA                               False   \n",
              "\n",
              "  FinInstrmGnlAttrbts.NtnlCcy   Issr  \n",
              "0                         EUR  False  \n",
              "1                         EUR  False  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DLTINS_20210119_02of02.csv has been uploaded to steeleyedataengineer successfully!\n",
            "DLTINS_20210119_01of02.csv has been uploaded to steeleyedataengineer successfully!\n",
            "DLTINS_20210117_01of01.csv has been uploaded to steeleyedataengineer successfully!\n",
            "DLTINS_20210118_01of01.csv has been uploaded to steeleyedataengineer successfully!\n"
          ]
        }
      ],
      "source": [
        "import boto3\n",
        "import os\n",
        "\n",
        "# Set up S3 client\n",
        "s3 = boto3.client('s3',\n",
        "                  aws_access_key_id='AKIAZPLSV4VZUKKKOOWM',\n",
        "                  aws_secret_access_key='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')\n",
        "\n",
        "bucket_name = 'steeleyedataengineer'\n",
        "dir_path = './Data/'\n",
        "\n",
        "for filename in os.listdir(dir_path):\n",
        "    if filename.endswith('.csv'):\n",
        "\n",
        "        # Upload the file to S3 bucket\n",
        "        s3.upload_file(os.path.join(dir_path, filename), bucket_name, filename)\n",
        "        print(f\"{filename} has been uploaded to {bucket_name} successfully!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
